# LLM Settings
# Use mock client for development/testing (true/false)
DEBUG=true
USE_MOCK_LLM=true

# For production with real Ollama API
# DEBUG=false
# USE_MOCK_LLM=false
# OLM_API_ENDPOINT=http://localhost:8000
# OLLAMA_MODEL=qwen3:0.6b

# LLM Processing Settings
USE_TWO_STAGE_LLM=true
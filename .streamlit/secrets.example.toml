DEBUG = true
USE_LOCAL_CLIENT = false

OLM_API_ENDPOINT = "http://localhost:11434"
OLLAMA_MODEL = "qwen3:0.6b"

# --- Analysis Configuration ---
ARGUMENT_FLOW_DIVISOR = 4           # Divisor for argument flow summary length
TARGET_SLIDE_COUNT = 3             # Default target slide count for presentations

# --- Prompt Configuration ---
MAX_PROMPT_LENGTH = 8000            # Maximum prompt length to prevent context overflow

# --- Timeout Configuration (in seconds) ---
LLM_TIMEOUT = 1200              # LLM request timeout
CHAIN_TIMEOUT = 2400            # Complete chain execution timeout
 

# --- Streamlit Configuration ---
HOST_IP = "127.0.0.1"
TEST_PORT = "8502"
DEV_PORT = "8503"



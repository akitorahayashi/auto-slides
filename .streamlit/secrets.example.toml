# --- Debug Configuration ---
DEBUG = true

# --- LLM Configuration ---
USE_TWO_STAGE_LLM = true
USE_DEMO_RESPONSES = true  # 固定デモレスポンスを使用（展示・テスト用）

# For production with real Ollama API (set DEBUG=false and USE_DEMO_RESPONSES=false)
# OLM_API_ENDPOINT = "http://localhost:8000"
# OLLAMA_MODEL = "qwen3:0.6b"

# --- Streamlit Configuration ---
HOST_IP = "127.0.0.1"
TEST_PORT = "8502"
DEV_PORT = "8503"


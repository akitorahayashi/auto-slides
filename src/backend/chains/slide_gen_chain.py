import inspect
from typing import Any, Callable, Dict, List, Optional

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough

from src.backend.models.slide_template import SlideTemplate
from src.backend.services import JsonParser, PromptService, SlidesLoader
from src.protocols.protocols.olm_client_protocol import OlmClientProtocol
from src.protocols.slide_generation_protocol import SlideGenerationProtocol


class SlideGenChain(SlideGenerationProtocol):
    """LangChain LCEL chains for slide generation workflow"""

    def __init__(
        self,
        llm: OlmClientProtocol,
        progress_callback: Optional[Callable[[str, int, int], None]] = None,
    ):
        """
        Initialize slide generation chain.

        Args:
            llm: Required OlmClientProtocol implementation for text generation
            progress_callback: Optional callback function to report progress (stage, current, total)
        """
        self.llm = llm
        self.json_parser = JsonParser()
        self.str_parser = StrOutputParser()
        self.prompt_service = PromptService()
        self.slides_loader = SlidesLoader()
        self.progress_callback = progress_callback
        self.current_request = 0
        self.total_requests = 0
        self._setup_chains()

    def _create_chain_step(self, prompt_builder_method):
        """Create a standardized chain step"""
        return (
            RunnablePassthrough.assign(prompt=RunnableLambda(prompt_builder_method))
            | RunnableLambda(lambda x: x["prompt"])
            | RunnableLambda(
                lambda prompt_dict: {
                    **prompt_dict,
                    "prompt": self.prompt_service._truncate_prompt(
                        prompt_dict["prompt"]
                    ),
                }
            )
            | ChatPromptTemplate.from_template("{prompt}")
            | RunnableLambda(lambda x: self._increment_request_counter() or x)
            | self.llm
            | self.json_parser
        )

    def _increment_request_counter(self):
        """LLMãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ """
        self.current_request += 1
        if self.progress_callback:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚’0.0-1.0ã§è¨ˆç®—
            progress = min(self.current_request / max(self.total_requests, 1), 1.0)
            print(
                f"ğŸ“Š LLM Request {self.current_request}/{self.total_requests} (progress: {progress:.1%})"
            )
            # ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã‚’æ±ºå®š
            if self.current_request == 1:
                stage = "analyzing"
            elif self.current_request == 2:
                stage = "composing"
            else:
                stage = "generating"
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‘¼ã³å‡ºã—ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤–ã§ã®å‘¼ã³å‡ºã—ã‚’å›é¿ï¼‰
            try:
                self.progress_callback(stage, self.current_request, self.total_requests)
            except Exception as e:
                print(f"Progress callback failed: {e}")
        return None

    def _setup_chains(self):
        """Setup unified slide generation chain"""
        self.slide_gen_chain = (
            # Phase 1: Analysis
            RunnablePassthrough.assign(
                analysis_result=self._create_chain_step(
                    self.prompt_service.build_analysis_prompt
                )
            )
            # Phase 2: Composition
            | RunnablePassthrough.assign(
                slide_functions_summary=RunnableLambda(
                    lambda x: self.slides_loader.create_slide_functions_summary(
                        x["template"].id
                    )
                )
            )
            | RunnableLambda(lambda x: self._report_progress("composing") or x)
            | RunnablePassthrough.assign(
                composition_plan=self._create_chain_step(
                    self.prompt_service.build_composition_prompt
                )
            )
            # Phase 3: Parameter Generation & Execution
            | RunnableLambda(self._execute_slides)
            # Phase 4: Combine slides
            | RunnableLambda(lambda x: self._combine_slides(x["slides"]))
        )

    def invoke_slide_gen_chain(
        self, script_content: str, template: SlideTemplate
    ) -> str:
        """Unified slide generation chain execution"""
        try:
            # äº‹å‰ã«LLMãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’è¨ˆç®—
            self._calculate_total_requests(template)
            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’1ã‹ã‚‰é–‹å§‹ã™ã‚‹ãŸã‚ã«åˆæœŸåŒ–
            self.current_request = 0
            self._report_progress("analyzing")
            print("ğŸ” Agent: Analyzing script content...")

            input_data = {"script_content": script_content, "template": template}
            print(
                f"ğŸ” Input data: script_length={len(script_content)}, template_id={template.id}"
            )
            print(f"ğŸ” Total LLM requests: {self.total_requests}")

            result = self.slide_gen_chain.invoke(input_data)
            self._report_progress("completed")
            print("ğŸ‰ Agent: Presentation generated successfully!")
            print(f"ğŸ” Result length: {len(result) if result else 0}")
            return result
        except Exception as e:
            print(f"ğŸš¨ Agent error: {e}")
            print(f"ğŸš¨ Error type: {type(e).__name__}")
            print(
                f"ğŸš¨ Input was: script_length={len(script_content) if script_content else 0}, template_id={template.id if template else 'None'}"
            )
            raise e

    def _calculate_total_requests(self, template: SlideTemplate) -> None:
        """äº‹å‰ã«LLMãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’è¨ˆç®—"""
        try:
            # åŸºæœ¬çš„ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆ: åˆ†æ(1) + æ§‹æˆ(1) = 2
            base_requests = 2

            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé–¢æ•°ã®æ•°ã‚’å–å¾—ï¼ˆã“ã‚Œã¯åˆ©ç”¨å¯èƒ½ãªé–¢æ•°æ•°ã§ã‚ã‚Šã€å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã‚‹æ•°ã§ã¯ãªã„ï¼‰
            functions = self.slides_loader.load_template_functions(template.id)

            # åˆæœŸå€¤ã¨ã—ã¦åˆ©ç”¨å¯èƒ½ãªé–¢æ•°æ•°ã‚’ä½¿ç”¨ï¼ˆå¾Œã§å‹•çš„ã«èª¿æ•´ï¼‰
            # å®Ÿéš›ã®å€¤ã¯ composition_plan å–å¾—å¾Œã«æ›´æ–°ã•ã‚Œã‚‹
            estimated_slide_count = len(functions)

            # å„ã‚¹ãƒ©ã‚¤ãƒ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
            parameter_requests = estimated_slide_count

            self.total_requests = base_requests + parameter_requests
            self.current_request = 0

            print(
                f"ğŸ”¢ Initial request calculation: {self.total_requests} (base: {base_requests}, estimated slides: {estimated_slide_count})"
            )
        except Exception as e:
            print(f"âš ï¸ Error calculating requests: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            self.total_requests = 5
            self.current_request = 0

    def _execute_slides(self, context: Dict) -> Dict:
        """Execute slide generation from composition plan"""
        print("âœï¸ Agent: Generating slide parameters...")

        composition_plan = context["composition_plan"]
        template = context["template"]
        script_content = context["script_content"]
        analysis_result = context["analysis_result"]

        # composition_planã‹ã‚‰å®Ÿéš›ã®ã‚¹ãƒ©ã‚¤ãƒ‰æ•°ã‚’å–å¾—ã—ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’æ›´æ–°
        slides_list = composition_plan.get("slides", [])
        actual_slide_count = len(slides_list)

        if actual_slide_count > 0:
            # å®Ÿéš›ã®ã‚¹ãƒ©ã‚¤ãƒ‰æ•°ã«åŸºã¥ã„ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’å†è¨ˆç®—
            base_requests = 2  # åˆ†æ(1) + æ§‹æˆ(1)
            new_total_requests = base_requests + actual_slide_count

            print(
                f"ğŸ”„ Updating total requests: {self.total_requests} â†’ {new_total_requests} (actual slides: {actual_slide_count})"
            )
            self.total_requests = new_total_requests
        else:
            print(
                f"âš ï¸ No slides found in composition plan, using original estimate: {self.total_requests}"
            )

        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹è¡¨ç¤ºã‚’æ›´æ–°ï¼ˆç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã§æœ€æ–°ã®åˆ†æ¯ã‚’è¡¨ç¤ºï¼‰
        self._report_progress("generating")

        slide_parameters = []
        functions = self.slides_loader.load_template_functions(template.id)

        # composition_planã®æ§‹é€ ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        print(f"ğŸ” Composition plan structure: {composition_plan}")
        print(f"ğŸ” Slides list: {slides_list}")

        for i, slide_plan in enumerate(slides_list):
            print(f"ğŸ” Processing slide {i + 1}: {slide_plan}")

            # slide_nameã®å­˜åœ¨ç¢ºèª
            if not isinstance(slide_plan, dict):
                print(f"âš ï¸ Slide plan {i + 1} is not a dictionary: {type(slide_plan)}")
                continue

            slide_name = slide_plan.get("slide_name")
            if not slide_name:
                print(f"âš ï¸ Slide plan {i + 1} missing slide_name: {slide_plan}")
                continue

            if slide_name not in functions:
                print(f"âš ï¸ Function '{slide_name}' not available in template functions")
                continue

            try:
                params = self._create_chain_step(
                    self.prompt_service.build_parameter_prompt
                ).invoke(
                    {
                        "script_content": script_content,
                        "analysis_result": analysis_result,
                        "slide_name": slide_name,
                        "function_info": functions[slide_name],
                    }
                )
                slide_parameters.append(params)
                print(f"âœ… Successfully generated parameters for {slide_name}")
            except Exception as param_error:
                print(f"âš ï¸ Error generating parameters for {slide_name}: {param_error}")
                continue

        self._report_progress("building")
        print("ğŸ—ï¸ Agent: Building slides...")
        slides = []

        for i, slide_param in enumerate(slide_parameters):
            print(f"ğŸ” Processing slide parameter {i + 1}: {slide_param}")

            if not isinstance(slide_param, dict):
                print(f"âš ï¸ Slide param {i + 1} is not a dictionary: {type(slide_param)}")
                continue

            slide_name = slide_param.get("slide_name")
            if not slide_name:
                print(f"âš ï¸ Slide param {i + 1} missing slide_name: {slide_param}")
                continue

            parameters = slide_param.get("parameters", {})

            func = self.slides_loader.get_function_by_name(template.id, slide_name)

            if func:
                try:
                    # é–¢æ•°ã®ã‚·ã‚°ãƒãƒãƒ£ã‚’å–å¾—ã—ã¦ã€æœ‰åŠ¹ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’æ¸¡ã™
                    sig = inspect.signature(func)
                    valid_params = {}

                    for param_name, param_value in parameters.items():
                        if param_name in sig.parameters:
                            valid_params[param_name] = param_value
                        else:
                            print(
                                f"ğŸ”§ Skipping invalid parameter '{param_name}' for function '{slide_name}'"
                            )

                    # ä¸è¶³ã—ã¦ã„ã‚‹å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯
                    missing_params = []
                    for param_name, param in sig.parameters.items():
                        if (
                            param.default is inspect.Parameter.empty
                            and param_name not in valid_params
                        ):
                            missing_params.append(param_name)

                    if missing_params:
                        print(
                            f"âš ï¸ Missing required parameters for {slide_name}: {missing_params}"
                        )
                        continue

                    slide_content = func(**valid_params)
                    slides.append(slide_content)
                except Exception as e:
                    print(f"âš ï¸ Error executing {slide_name}: {e}")
                    print(f"   Parameters: {parameters}")
                    print(
                        f"   Valid parameters: {valid_params if 'valid_params' in locals() else 'N/A'}"
                    )
                    continue

        return {**context, "slides": slides}

    def _combine_slides(self, slides: List[str]) -> str:
        """Combine individual slides into complete presentation"""
        self._report_progress("combining")

        processed_slides = []
        for slide in slides:
            processed_slides.append(slide.rstrip("\n-"))

        return "\n\n".join(processed_slides)

    def _report_progress(self, stage: str):
        """Report progress to callback if available"""
        if self.progress_callback:
            # å®Œäº†æ™‚ã¯æœ€å¤§å€¤ã«è¨­å®šã€ãã‚Œä»¥å¤–ã¯ç¾åœ¨ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°+1ã‚’è¡¨ç¤ºï¼ˆ1ã‹ã‚‰å§‹ã¾ã‚‹ãŸã‚ï¼‰
            if stage == "completed":
                current = self.total_requests
            else:
                current = self.current_request + 1  # 1ã‹ã‚‰å§‹ã¾ã‚‹ã‚ˆã†ã«è¡¨ç¤º
            self.progress_callback(stage, current, self.total_requests)
